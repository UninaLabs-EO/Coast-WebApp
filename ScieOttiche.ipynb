{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ScieOttiche.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UninaLabs-EO/Coast-WebApp/blob/main/ScieOttiche.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Torch - Torchvision - IceVision - IceData - MMDetection - YOLOv5 - EfficientDet Installation\n",
        "!wget https://raw.githubusercontent.com/airctic/icevision/master/icevision_install.sh\n",
        "\n",
        "# Choose your installation target: cuda11 or cuda10 or cpu\n",
        "!bash icevision_install.sh cuda11\n",
        "\n",
        "!pip install pillow==4.1.1"
      ],
      "metadata": {
        "id": "UBketpJhEq7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Restart kernel after installation\n",
        "import IPython\n",
        "IPython.Application.instance().kernel.do_shutdown(True)"
      ],
      "metadata": {
        "id": "AuYToi5_FRAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jHyjIQBcdpCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from icevision.all import *"
      ],
      "metadata": {
        "id": "IPe_G13eHBDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "coco_dir = Path('/content/drive/MyDrive/DATASET/data')\n",
        "parser = parsers.COCOBBoxParser(coco_dir / \"Annotations/train.json\", coco_dir / \"Immagini_train\")"
      ],
      "metadata": {
        "id": "4yZvQE4BHHyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the parser\n",
        "# parser = parsers.VOCBBoxParser(annotations_dir=data_dir / \"odFridgeObjects/annotations\", images_dir=data_dir / \"odFridgeObjects/images\")"
      ],
      "metadata": {
        "id": "L2OZGlayIxiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parse annotations to create records\n",
        "train_records, valid_records = parser.parse()\n",
        "parser.class_map"
      ],
      "metadata": {
        "id": "A0Sq16U6I9fi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforms\n",
        "# size is set to 384 because EfficientDet requires its inputs to be divisible by 128\n",
        "image_size = 384\n",
        "train_tfms = tfms.A.Adapter([*tfms.A.aug_tfms(size=image_size, presize=512), tfms.A.Normalize()])\n",
        "valid_tfms = tfms.A.Adapter([*tfms.A.resize_and_pad(image_size), tfms.A.Normalize()])"
      ],
      "metadata": {
        "id": "1uoAMCEAJG4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Datasets\n",
        "train_ds = Dataset(train_records, train_tfms)\n",
        "valid_ds = Dataset(valid_records, valid_tfms)"
      ],
      "metadata": {
        "id": "oWrQyQKvJMB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show an element of the train_ds with augmentation transformations applied\n",
        "samples = [train_ds[0] for _ in range(3)]\n",
        "show_samples(samples, ncols=3)"
      ],
      "metadata": {
        "id": "yIg4ePJTJRtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = models.mmdet.vfnet\n",
        "backbone = model_type.backbones.resnet50_fpn_1x(pretrained=True)"
      ],
      "metadata": {
        "id": "hajUctpbJguj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Just change the value of selection to try another model\n",
        "\n",
        "selection = 0\n",
        "\n",
        "extra_args = {}\n",
        "\n",
        "if selection == 0:\n",
        "  model_type = models.mmdet.vfnet\n",
        "  backbone = model_type.backbones.resnet50_fpn_mstrain_2x\n",
        "\n",
        "if selection == 1:\n",
        "  model_type = models.mmdet.retinanet\n",
        "  backbone = model_type.backbones.resnet50_fpn_1x\n",
        "  # extra_args['cfg_options'] = { \n",
        "  #   'model.bbox_head.loss_bbox.loss_weight': 2,\n",
        "  #   'model.bbox_head.loss_cls.loss_weight': 0.8,\n",
        "  #    }\n",
        "\n",
        "if selection == 2:\n",
        "  model_type = models.mmdet.faster_rcnn\n",
        "  backbone = model_type.backbones.resnet101_fpn_2x\n",
        "  # extra_args['cfg_options'] = { \n",
        "  #   'model.roi_head.bbox_head.loss_bbox.loss_weight': 2,\n",
        "  #   'model.roi_head.bbox_head.loss_cls.loss_weight': 0.8,\n",
        "  #    }\n",
        "\n",
        "if selection == 3:\n",
        "  model_type = models.mmdet.ssd\n",
        "  backbone = model_type.backbones.ssd300\n",
        "\n",
        "if selection == 4:\n",
        "  model_type = models.mmdet.yolox\n",
        "  backbone = model_type.backbones.yolox_s_8x8\n",
        "\n",
        "if selection == 5:\n",
        "  model_type = models.mmdet.yolof\n",
        "  backbone = model_type.backbones.yolof_r50_c5_8x8_1x_coco\n",
        "\n",
        "if selection == 6:\n",
        "  model_type = models.mmdet.detr\n",
        "  backbone = model_type.backbones.r50_8x2_150e_coco\n",
        "\n",
        "if selection == 7:\n",
        "  model_type = models.mmdet.deformable_detr\n",
        "  backbone = model_type.backbones.twostage_refine_r50_16x2_50e_coco\n",
        "\n",
        "if selection == 8:\n",
        "  model_type = models.mmdet.fsaf\n",
        "  backbone = model_type.backbones.x101_64x4d_fpn_1x_coco\n",
        "\n",
        "if selection == 9:\n",
        "  model_type = models.mmdet.sabl\n",
        "  backbone = model_type.backbones.r101_fpn_gn_2x_ms_640_800_coco\n",
        "\n",
        "if selection == 10:\n",
        "  model_type = models.mmdet.centripetalnet\n",
        "  backbone = model_type.backbones.hourglass104_mstest_16x6_210e_coco\n",
        "\n",
        "elif selection == 11:\n",
        "  # The Retinanet model is also implemented in the torchvision library\n",
        "  model_type = models.torchvision.retinanet\n",
        "  backbone = model_type.backbones.resnet50_fpn\n",
        "\n",
        "elif selection == 12:\n",
        "  model_type = models.ross.efficientdet\n",
        "  backbone = model_type.backbones.tf_lite0\n",
        "  # The efficientdet model requires an img_size parameter\n",
        "  extra_args['img_size'] = image_size\n",
        "\n",
        "elif selection == 13:\n",
        "  model_type = models.ultralytics.yolov5\n",
        "  backbone = model_type.backbones.small\n",
        "  # The yolov5 model requires an img_size parameter\n",
        "  extra_args['img_size'] = image_size\n",
        "\n",
        "model_type, backbone, extra_args"
      ],
      "metadata": {
        "id": "Pf3F66ohJ02T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone.__dict__"
      ],
      "metadata": {
        "id": "Yt4iq8sSK83K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate the model\n",
        "model = model_type.model(backbone=backbone(pretrained=True), num_classes=len(parser.class_map), **extra_args) \n"
      ],
      "metadata": {
        "id": "L_pmDyNILUBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loaders\n",
        "train_dl = model_type.train_dl(train_ds, batch_size=8, num_workers=4, shuffle=True)\n",
        "valid_dl = model_type.valid_dl(valid_ds, batch_size=8, num_workers=4, shuffle=False)"
      ],
      "metadata": {
        "id": "RZ2hQ_kZLWmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show batch\n",
        "model_type.show_batch(first(valid_dl), ncols=4)"
      ],
      "metadata": {
        "id": "tY7Li857L4SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = [COCOMetric(metric_type=COCOMetricType.bbox)]"
      ],
      "metadata": {
        "id": "W6Sn7mhOL6hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training using fastai"
      ],
      "metadata": {
        "id": "v4z3EX1sNafW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn = model_type.fastai.learner(dls=[train_dl, valid_dl], model=model, metrics=metrics)"
      ],
      "metadata": {
        "id": "ZIN366sGMAWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "\n",
        "# For Sparse-RCNN, use lower `end_lr`\n",
        "# learn.lr_find(end_lr=0.005)"
      ],
      "metadata": {
        "id": "b3eczIVyMEsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fine_tune(20, 0.00158, freeze_epochs=1)"
      ],
      "metadata": {
        "id": "wixXVG9tNRtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_dl = model_type.infer_dl(valid_ds, batch_size=4, shuffle=False)\n",
        "preds = model_type.predict_from_dl(model, infer_dl, keep_images=True)"
      ],
      "metadata": {
        "id": "GggqnQ38O74W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_type.show_results(model, valid_ds, detection_threshold=.5)"
      ],
      "metadata": {
        "id": "Sr0ZI4iQPHJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_preds(preds=preds[:2])"
      ],
      "metadata": {
        "id": "RHNYuRFQO8Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DyTTao_RO9zJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}